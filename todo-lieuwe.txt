====    TODO

Documentation:
    HighLabelpauli
    getStabilizerGeneratorSet

-- coding, functionality

incorporate X,Y cases into getIsomorphism's case u==v, see branch limdd-pauli-better-isomorphisms

ask Thomas, Stefan how to decrease refcount to a node, so that the previous node is deleted, in the knife case of normalizeLIMDDPauli().

add Pauli-LIMDD functionality to
    ComputeTable of Add
    ComputeTable of multiplyMatrix
    make inventory of places where LIMDD functionality needs to be added in order to support simulation

bool isTower()

Remove memory leaks
    make inventory of memory leaks

--  INVENTORY OF MEMORY LEAKS

in normalizeLIMDDPauli:
    (done) via lots of LimEntry<>::multiply calls
    - root node label should be a local variable; then it is looked up.
    (done) high label is newly allocated; but is not necessary
    - use leftMultiplyBy instead of LimEntry<>::multiply
    many complex values are not returned to the cache
in getIsomorphismPauli, :
    - return a LimEntry<> by value
    - use a separate bit to indicate whether the isomorphism was found?
in getHighlabel:
    (done) return a LimEntry<> by value
in constructStabilizerGeneratorSetPauli:
    ?
in makeDDNode:
    (done) put the LIMs of the stabilizer generator group in the LimTable
    delete the LIMs
    construct the stabilizer group ONLY if it was not previously computed
getCosetIntersectionElementPauli
    - LimEntry<>::multiply; solution is to use local LIMs
    - return a LimEntry object by value
    - use a separate bit to indicate whether the isomorphism was found?
getCosetIntersectionModuloPhase:
    return a LimEntry<> by value
groupConcatenate
    return std::vector<LimEntry<> > instead of vector<LimEntry<>*>
appendIdentityMatrixBitset:
    return vector<LimBitset> instead of vector<LimBitset*>
getKernelModuloPhase:
    do everything by value
getProductofElements:
    return entry by value
GaussianElimination:
    do multiplyBy instead of Limentry<>::multiply
in LimWeight
    make the LimEntry<> object a data field instead of a pointer
GramSchmidt
    - return by value


-- TESTS

test for isTower

fuzz more circuits:
nqubits = 2 ... 5
    ngates = 5, 10, 15, 20, 25
        make 300 clifford circuits
        make 300 non-Clifford circuits

make tests for intersectGroupsPauli

Write many tests for
    GaussianElimination,
        when -I is generated
    getVector
write test for recoverPhase(G, a)
write test for recoverElement

-- REFACTORING (low priority)

in new file PauliUtilities.hpp,
    put the easy Pauli algebra stuff, like printing groups,
    copying bitset segments, stuff with phases

refactor LimEntry<>::setOperator so that one function is called,
    instead of two different setOperators
    note that pauli_op is already defined in terms of 'I' and 'X' and so on, so it should already translate correctly

In getKernelZ, getKernelPauli,
    Refactor LimBitset* into LimBitset, i.e., make them local, temporary variables,
    to reduce memory management problems

Refactor 'limVector' into 'StabilizerGroup'
refactor StabilizerGroup into its own class
    Methods:
    GramSchmidt
    IsSorted
    Sort()
    getKernel
    appendIdentity
    equals
    concatenate
    deepcopy
    gaussianElimination
    pruneZeroColumns
    toColumnEchelonForm
    addLim
    	don't add duplicate LIMs

highLabelZ uses GramSchmidt(Group, LimEntry*)
    result is returned as pointer
    but we don't want to use it as pointer

rewrite GaussianElimination so that it takes into account the phase
    - toColumnEchelonForm(StabilizerGroup)
        - constructStabilizerGroupZ
            here -I cannot arise
        - getHighLabelZ 
            This method should use toColumnEchelonFormModuloPhase, right?
    in these applications, is it important to handle the case when -I is generated?
    If so, then neither of these methods will suffer from the "not handling -I correctly"-deficiency.

-- LOW PRIORITY

refactor CVec utilities into a separate file
    print
    is zero
    add
    multiply(CMat, CVec)
put sanity checks in a separate file

make Hamming weight circuits

getLIMDDFromVector() turn a ket-vector into a LIMDD
use some tests to test whether the isomorphism-finding machinery works:
vector := [ ... ]
iso := xyziy
transformedVector := iso * vector
LIMDD a := getLIMDDFromVector(vector)
LIMDD b := getLIMDDFromVector(vector)
isoFound := getIsomorphism(a, b)
if isValidIsomorphism(a, b, isoFound) party else error

in tests, call isIsomorphism instead of defining a handwritten isomorphism


====    DONE


All 'simpleCircuit' tests pass

Talk to Thomas and Jurgen about:
    - large groups, very large groups
Talk to Stefan about:
    - better variable reordering strategies

incorporate weights into the getIsomorphismPauli procedure
    Use a cached weight in getHighLabelPauli
    in normalizeLIMDDPauli, allocate a cached weight, weightInv that highLabel can use,
        so that highLabelPauli doesn't need to receive the whole complexTable
    do not assume that the low weight is 1 
    cover the case when u.high = 1 / v.high, in the spoon case when u.p == v.p
        work out on paper first

in normalizeLIMDD, in the high knife case, do we remove the high label, if it is present?
    it seemes counterintuitive to do, but we should set the label to I

- make 10 stabilizer circuits
- make 10 non-stabilizer circuits, with T gates

all tests pass under Pauli group

add <Z>-LIMDD functionality to
    add
    multiplyMatrix
    make inventory of places where LIMDD functionality needs to be added in order to support simulation

refactor getIsomorphismPauli so that it returns a LIM with a weight

refactor highLabelPauli so that it returns a LimWeight object, with the new weight and new LIM
    (maybe not, since the returnToCache() obligations on normalizeLIMDD() would be more complicated

Is the 's' and 'x' parameters useful?
    write this algorithm on paper, or find it in notebook
    If the 's' or 'x' is not used, then remove it from the highlabel parameters

make very detailed writeup of getIsomorphismPauli in pdf, explaining all the reasoning.
    This is also important for other people, and myself, to understand the algorithms.

implement 'follow' and 'unfollow' for the Pauli group
    amounts to implementing X and Y

in normalizeLIMDDPauli, in the knife cases, make sure the two edges point to the same node.

make functionality in Package which allows me to execute a circuit
refactor the simpleCliffordCircuit tests to first execute a circuit as qmdd, then as limdd; then compare the CVec of the final states

Log
    all debugging statements in the limdd go to Log instead of to std::cout
    ability to turn the log on and off

make a new reduction rule for weights on the high edge.
	communicate with Linz

// TODO is the assertion that the low LIMs are Identity true in all calls from normalizeLIMDD?
    Yes, this assertion holds when getIsomorphism is called

checkout testSimpleCliffordCircuit_1,2,3 in other branches to see if I've merged correctly

Take steps to fix the segmentation faults, invalid free errors
    make a vNode destructor, which does nothing.
    repair memory leaks in all the methods that need it, in PauliAlgebra.hpp
    (Sebastiaan fixed these)
    
The following tests fail:
[  FAILED  ] LimTest.simpleCliffordCircuit
    Because simulation is not yet supported; only representation is supported
[  FAILED  ] DDPackageTest.VectorSerializationTest
    Because serialize() and deserialize() do not support LIMDDs yet
[  FAILED  ] DDPackageTest.BasicNumericStabilityTest
    Because it stores the state |-> = |0> - |1>.
    It assumes the high edge weight will be -sqrt 2.
    However, with the new LIMDD functionality, this is stored as Z|+>  =  Z(|0> + |1>),
    so the weight is +sqrt 2 instead of -sqrt 2.

Add a parameter to the dd stating the group, 'Z', 'Pauli', 'QMDD' / 'trivial'
    refactor the group to enum LIMDD_group type



Ask Linz to help design the division and multiplications that are needed

fix test createnode9
    error has to do with getbit. what is going wrong?
fix test createnode11

Update getVectorLIMDD to reflect the X, and Y gates
write isValidIsomorphismBruteForce(edge, edge, lim), which outputs 'true' iff the given lim is an isomorphism between edge and edge

pass all PauliIsomorphism tests

Make a class "LimWeight" which contains (i) LimEntry; (ii) Complex
Output of getIsomorphismPauli is a struct called "LimWeight" with fields LimEntry, Complex

make an inventory of functionality that needs to be added to support the Pauli group

highLabelPauli
    sketch this algorithm on paper

Complex::lexSmallerThan

refactor 'phases' into 'phase_t'

make a list of usages of LimBitset
Here is the list:
    - getKernelModuloPhase
    - NOT in getKernel, but should we use it there? Does any procedure use that function? Here is a list:
    todo: in intersectGroups, use LimBitset instead of LimEntry
        should we do this?

remove GramSchmidt algorithms that are not used
    refactor usage of GramSchmidt(Group, LimBitset) into GramSchmidt(Group, LimEntry, std::bitset)
    result: all three are used. But one of them we can refactor:
    should we refactor GramSchmidt(G, x) { return GramSchmidt(G,x, std::bitset); } ?
GramSchmidt is used here:
    getCosetIntersectionElementPauli uses GramSchmidt(Group, LimBitset*)
        result is used as a local variable
        SOLVED has no memory leaks
    getCosetIntersectionElementPauli uses GramSchmidt(Group, LimEntry*, bitset)
        result is not used; only used to obtain the decomposition
        TODO: solve memory leak by using local variable.
        Don't return anything.


in PauliAlgebra.hpp: intersectGroupsModuloPhase:
    refactor loop body to getProductOfElements

in PauliAlgebra.hpp: GramSchmidt(LimBitset)
    refactor local variable y to stack instead of heap
    
in Package.hpp: normalizeLIMDD
    double-check whether the case when getIsomorphismZ returns the nullptr, is handled correctly

getVector

getIsomorphismZ when amplitudes have opposite signs, +/- 1
	when amplitude sign is hidden in the phase ( should not happen in reduced diagrams?)

refactor groupsIntersectZ to use getKernelBitset instead of getKernel

write getKernelZ to use Bitset instead of LimEntry

refactor GaussianElimination(LimBitset) to handle the phase appropriately, i.e.,
	if there's -I, then use that to cancel out all the other LIMs with a phase

In HighLabel, take the weight on the high edge as an input, and produce a new weight on the high edge as an output. (this also happens in the algorithm in the paper)
	Use the following lexmin order on complex numbers, a+bi, c+di:
		if b>d return a+bi
		if d>b return c+di
		if a>c return a+bi
		return c+di
	Sketch the HighLabel algorithm
	Implement the HighLabel algorithm
		
merge the branch of LIMs-in-reverse-order

in getIsomorphismZ:
	do the case when the amplitudes have opposite signs

implement toColumnEchelonFormModuloPhase

implement Coset Intersection Element Pauli

rewrite toColumnEchelonForm so that it keeps track of a 'linear combination matrix', using the LimBitset data structure

Add findAutomorphismGroup to makeDDNode

Write tests for
	ColumnEchelonForm
		1. Test G={ ZI, IZ, ZI, IZ }
    makeDDNode(edge 1, edge 2)
	automorphism group construction
	GramSchmidt
	coset intersection Pauli
		many tests exist in Python implementation
	multiplication, paying attention to phase
	making Pauli strings with phases
	getPhase
    Complex::multiplyByMinusOne()
	tests where nodes are normalized
		first successful test (not ending in segfault)
	    first successful test with a normalized node and a non-trivial edge label
    intersection tests; import from Python



multiplication

constructStabilizerGeneratorSetZ

coset intersection
    implement with less dynamic reallocation

highlabelZ

Write and pass the 8 tests (4 remaining)

update the paulitostring test

test the phase in the LimEntry constructor

update the bitsetfromstring test

getIsomorphismZ

in test CreateNode1:
	Find out why getIsomorphismZ doesn't find the isomorphism it's supposed to find

in a new branch, make LIMs the most significant bit

sort stabilizer groups descending instead of ascending




====    TODO new functionality to support Pauli    ====

** Tests **
- make 10 test cases for highLabelPauli
-     on paper
- make 10 test cases for getIsomorphismPauli
-     on paper
- make a test case for nodes which trigger Step 5 in getIsomorphismZ, the 'Z'-operator clause
- make a test case which triggers Step 5 in getIsomorphismPauli
- make a test case which triggers Case 3.1 in getIsomorphismPauli
- make a test case which triggers case 3.1, and which is sensitive to the weight
- make a test which triggers case x=1 in normalizeLIMDD

in normalizeLIMDD:
    + swap the two edges if necessary
    + find a total order on nodes... their ID?
    + use bool x in the getLabels function
    - in case x=1, multiply weight by lambda

getIsomorphismPauli
    + modify getIsomorphismZ by checking whether maybe u and v need to be exchanged;
    + sketch this algorithm on paper
    + it looks like we have all the necessary elements, like intersect Pauli cosets
    - multiply with 1/w

getStabilizerGeneratorSetPauli
    + work out on paper
    + implement
    + call from normalize

GaussianEliminationPauli
    hypothesis: already works.
    - Write tests to check if we're left-multiplying or right-multiplying and whether that matters (given that our groups are abelian)

getRootLabel
    Hypothesis: already works for Pauli
        since it just returns the lexmin of a coset, which is what we want

toColumnEchelonFormPauli
    Hypothesis: works after we refactor GaussianEliminationPauli (if necessary)

GramSchmidt
    Hypothesis: already works.
    - make some tests to check that idea

getKernelPauli
    Hypothesis: works after we refactor GaussianEliminationPauli (if necessary)

getKernelModuloPhase
    hypothesis: it already works, because it works if GaussianEliminationModuloPhase works

intersectGroupsPauli
    Write 10 tests to test this behaviour
    Refactor this to ask for getKernelPauli
    Hypothesis: it works when getKernelPauli works
    Double-check whether getProductOfElements should do left or right multiplication

Ask whether the number of qubits in the diagram 'nq' is different from the number of qubits for LIMs

====    TODO for which I need JKU's help

prepare Linz meeting
    new edge weight normalization rules; make a picture illustrating why this is
    make list of places in code where LimTable should be added

PauliAlgebra.hpp: implement several algorithms without a memory leak:
	- GramSchmidt
		Can be implemented with almost no reallocation of memory
		e.g., the 'y' object can be a local variable, instead of a pointer
	- GaussianElimination(LimEntry)
	   the following line may introduce a memory leak, by allocating a new LimEntry without deallocating the previous content of G[reduceColId]
        G[reduceColId] = LimEntry<NUM_QUBITS>::multiply(G[reduceColId], G[reducingColId]);
	- GaussianEliminationModuloPhase
	   the same as above
	- GaussianElimination(LimBitset)
	   the same as above
	- almost any place where two LIMs are multiplied
	
PauliAlgebra.hpp: highLabelZWeight
	Here a weight is multiplied by -1, in the function
            weight.multiplyByMinusOne();
    Can this have unintended consequences if the CTEntry is also used by another weight elsewhere in the diagram?
    If so, we should refactor this line to have no unintended consequences

PauliAlgebra.hpp: constuctStabilizerGeneratorSetZ
	deallocate 'm' and 'minus'

Package.hpp: normalizeLIMDD()
	1. two LIMs are multiplied in the following line in Step 1,
            r.p->e[1].l = LimEntry<>::multiply(lowLim, higLim);
	   This may introduce a memory leak; ideally, these LIMs are put in the table
       The same question for LimEntry<>::multiply in Step 5 and Step 7
    2. in Step 3, the procedure highLabelZ may change the weight on the high edge, by multiplying it by -1.
       Is this a violation of the normalization rules?
       --> see picture TODO
    3. In Step 6, the root edge weight is multiplied by -1.
       Can this have unintended consequences if the same weights are used elsewhere in the diagram?

PauliAlgebra.hpp: pruneZeroColumns
    This procedure removes LimEntry* pointers from a vector, without properly deallocating the LimEntry objects
    this procedure should reduce the refcount of the LimEntry objects it removes from G

PauliAlgebra.hpp: appendIdentityMatrixBitset
    allocates new LimBitset, but these objects are never deallocated.
    Solution: deallocate immediately after use, since they are temporary objects used locally in a function

PauliAlgebra.hpp: getKernelZ
    This procedure allocates LimBitset objects in the G_Id variable,
    but these objects are not deallocated.

in PauliAlgebra.hpp: getCosetIntersectionElementPauli
    The following local variables are allocated on the heap but not deallocated, causing memory leaks:
        GH
        GH_Id
        a_H
        a_prime
        k_G
        k_H

PauliAlgebra.hpp: constructStabilizerGeneratorSetZ
    put LimEntry pointers 'idZ' and 'minusIdZ' into the LimTable?
    deallocate 'minus' and 'm'

PauliAlgebra.hpp: isTimesMinusOne
    Should this method be moved to Complex.hpp?

PauliAlgebra.hpp: getIsomorphismZ
    'isoHigh' is allocated, but not deallocated.
    Put this object in the LimTable, or deallocate appropriately in some other way, e.g.,
    refactor into a local variable (on the stack)

PauliAlgebra.hpp: highLabelZ
    GH is not deallocated properly

in LimTable.hpp: LimEntry::multiply
    In the places that call this function, make sure that the LimEntry is put in the LimTable,
    if appropriate, and otherwise is deallocated
    make an inventory of places where this happens